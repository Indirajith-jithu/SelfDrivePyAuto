{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, json_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.json_dir = json_dir\n",
    "        self.json_data = [f for f in os.listdir(image_dir) if f.endswith(('.json', '.json'))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.json_data)\n",
    "    \n",
    "    def load_mask_from_json(self, json_path):\n",
    "        with open(json_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        mask = np.zeros((data['imageHeight'], data['imageWidth']), dtype=np.uint8)\n",
    "        for shape in data['shapes']:\n",
    "            points = np.array(shape['points'], dtype=np.int32)\n",
    "            mask = cv2.fillPoly(mask, [points], 1)\n",
    "        return mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load mask\n",
    "        data_name = self.json_data[idx]\n",
    "        json_path = os.path.join(self.json_dir, data_name)\n",
    "        mask = self.load_mask_from_json(json_path)\n",
    "\n",
    "        img_path = os.path.join(self.image_dir, data_name.replace( '.json', '.jpg'))\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        image = transform(image)\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class UNetWithBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetWithBN, self).__init__()\n",
    "        \n",
    "        # Encoder Block 1\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 12, 3, padding=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Encoder Block 2\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(12, 24, 3, padding=1),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Encoder Block 3\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.Conv2d(24, 34, 3, padding=1),\n",
    "            nn.BatchNorm2d(34),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Decoder Block 3\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.Conv2d(34, 24, 3, padding=1),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Decoder Block 2\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(24, 12, 3, padding=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        # Final layer\n",
    "        self.final = nn.Conv2d(12, 1, 1)\n",
    "        \n",
    "        # Pooling and Upsampling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool(e1)\n",
    "        \n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool(e2)\n",
    "        \n",
    "        e3 = self.enc3(p2)\n",
    "        \n",
    "        # Decoder\n",
    "        d3 = self.dec3(self.up(e3))\n",
    "        d2 = self.dec2(self.up(d3))\n",
    "        \n",
    "        out = self.final(d2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with added metrics\n",
    "def train_model(image_dir, json_dir, num_epochs=10):\n",
    "    # Create dataset and dataloader\n",
    "    dataset = SegmentationDataset(image_dir, json_dir)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "    \n",
    "    # Initialize model, loss, and optimizer\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetWithBN().to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (images, masks) in enumerate(dataloader):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).unsqueeze(1)\n",
    " \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Print batch progress\n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}/{num_epochs}, Batch {i}/{len(dataloader)}, '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {epoch_loss:.4f}')\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(epoch_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        # if epoch_loss < best_loss:\n",
    "        #     best_loss = epoch_loss\n",
    "        #     torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infernece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_path):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prediction = torch.sigmoid(output) > 0.5\n",
    "    \n",
    "    return prediction.cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pred_dir = 'sample image'\n",
    "mask = predict(model, pred_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(plt.imread(pred_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'best_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### infernce on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def process_video(model_path, video_path, output_path):\n",
    "    # Load model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = UNetWithBN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)    \n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "\n",
    "        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        input_tensor = transform(frame_pil).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            pred_mask = torch.sigmoid(output) > 0.5\n",
    "            pred_mask = pred_mask.squeeze().cpu().numpy()\n",
    "\n",
    "        pred_mask = cv2.resize(pred_mask.astype(np.uint8), (frame_width, frame_height))\n",
    "\n",
    "        colored_mask = np.zeros_like(frame)\n",
    "        colored_mask[pred_mask == 1] = [0, 255, 0]  # Green color for segmentation\n",
    "\n",
    "        alpha = 0.5\n",
    "        output_frame = cv2.addWeighted(frame, 1, colored_mask, alpha, 0)\n",
    "\n",
    "        out.write(output_frame)\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path =   # Path to your trained model\n",
    "    video_path =  # Path to your input video\n",
    "    output_path =  # Path for saving the output video\n",
    "    \n",
    "    process_video(model_path, video_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
